{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing for wt10g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./wt10g.spec') as file:\n",
    "    files = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucene\n",
    "from org.apache.lucene.analysis.en import EnglishAnalyzer\n",
    "from org.apache.lucene.index import IndexWriter, IndexWriterConfig\n",
    "from org.apache.lucene.store import FSDirectory\n",
    "import org.apache.lucene.document as document\n",
    "from java.io import File\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7fc38c39f0b0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucene.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexPath = File(\"index_wt10g_cleaned\").toPath()\n",
    "indexDir = FSDirectory.open(indexPath)\n",
    "\n",
    "analyzer = EnglishAnalyzer()\n",
    "writerConfig = IndexWriterConfig(analyzer)\n",
    "writer = IndexWriter(indexDir, writerConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tag_exp = re.compile('<.*?>', re.DOTALL)\n",
    "\n",
    "docCount = 0\n",
    "\n",
    "def cleanTag(rawDoc):\n",
    "    \n",
    "    cleanDoc = re.sub(tag_exp, '', rawDoc)\n",
    "    return cleanDoc\n",
    "\n",
    "def process(oneDoc):\n",
    "    global docCount\n",
    "    docCount += 1\n",
    "    # print(docCount)\n",
    "    return cleanTag(oneDoc)\n",
    "\n",
    "\n",
    "# this function needs to be called for each of the files in the directory\n",
    "def processFile(filePath):\n",
    "    with open(filePath, 'r', encoding='ISO-8859-1') as f:\n",
    "        inDoc = False\n",
    "        docid,oneDoc = \"\",\"\"\n",
    "        docids,contents = [],[]     # will store all the docs (docIDs, Contents) of a single file in a list\n",
    "                                    # with docid and contents in one-to-one list index-wise correspondence\n",
    "                                    # Why making lists? See the note in the next cell.\n",
    "        dochdr_flag = 0\n",
    "        for line in f:\n",
    "            if inDoc:\n",
    "                if line.startswith(\"<DOCNO>\"):\n",
    "                    m = re.search('<DOCNO>(.+?)</DOCNO>', line)\n",
    "                    docid = m.group(1)\n",
    "                    continue\n",
    "                elif line.strip() == \"</DOC>\":\n",
    "                    inDoc = False\n",
    "                    contents.append(process(oneDoc))\n",
    "                    docids.append(docid.strip())\n",
    "                    oneDoc = \"\"\n",
    "                else:\n",
    "                    if line.startswith(\"<DOCHDR>\") or line.startswith(\"<DOCOLDNO>\"):\n",
    "                        dochdr_flag += 1\n",
    "                    if dochdr_flag != 0:\n",
    "                        if line.startswith(\"</DOCHDR>\") or line.startswith(\"</DOCOLDNO>\"):\n",
    "                            dochdr_flag = 0\n",
    "                    if dochdr_flag == 0:\n",
    "                        oneDoc += line\n",
    "\n",
    "            elif line.strip() == \"<DOC>\":\n",
    "                inDoc = True\n",
    "        return docids,contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "di , dc = processFile(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "from org.apache.lucene.document import FieldType\n",
    "from org.apache.lucene.index import IndexOptions\n",
    "\n",
    "ft = FieldType()\n",
    "ft.setStored(True)\n",
    "ft.setTokenized(True)\n",
    "ft.setStoreTermVectors(True)\n",
    "# ft.setStoreTermVectorOffsets(True)\n",
    "# ft.setStoreTermVectorPositions(True)\n",
    "ft.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS)\n",
    "\n",
    "ftc = FieldType()\n",
    "ftc.setStored(True)\n",
    "\n",
    "# Main Indexer function\n",
    "def make_inverted_index(filePaths, fieldType, ftc):\n",
    "    for filePath in filePaths:\n",
    "        docids,contents = processFile(filePath)\n",
    "        for i in range(len(docids)):\n",
    "            doc = document.Document()\n",
    "            doc.add(document.Field('ID', docids[i], ftc))\n",
    "            doc.add(document.Field('CONTENTS', contents[i], fieldType))\n",
    "            writer.addDocument(doc)\n",
    "    writer.close()\n",
    "    print('Indexing completed successfully!')\n",
    "\n",
    "make_inverted_index(files, ft, ftc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
