{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize.regexp import blankline_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# lucene imports\n",
    "import lucene\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.index import DirectoryReader\n",
    "from org.apache.lucene.store import FSDirectory, SimpleFSDirectory\n",
    "from java.io import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f0a8c8fb070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start lucene virtual machine\n",
    "lucene.initVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class returns a corpus document field content generator (as an iterator)\n",
    "class MyCorpus:\n",
    "    def __init__(self, indexPath, fieldname):\n",
    "        # Corpus documents directory path\n",
    "        directory = FSDirectory.open(File(indexPath).toPath())\n",
    "        self.indexReader = DirectoryReader.open(directory)\n",
    "        self.numDocs = self.indexReader.numDocs()   # no. docs in English Wikipedia or its index\n",
    "        self.FIELDNAME = fieldname\n",
    "        self.bad_docid = 1053350\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for luceneDocid in range(self.bad_docid):\n",
    "            yield self.indexReader.document(luceneDocid).get(self.FIELDNAME)\n",
    "        # excluded bad_docid document \n",
    "        # which was throwing `SystemError: invalid maximum character passed to PyUnicode_New`\n",
    "        for luceneDocid in range(self.bad_docid+1,self.numDocs):\n",
    "            yield self.indexReader.document(luceneDocid).get(self.FIELDNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDNAME = 'CONTENT'       # Lucene index field name for content of the doc\n",
    "index_path = './Wikipedia-pages/index-enwiki'   # Lucene index directory path\n",
    "\n",
    "# enwiki doc generator object\n",
    "enwiki_corpus = MyCorpus(index_path, FIELDNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDNAME = 'CONTENT'       # Lucene index field name for content of the doc\n",
    "index_path = './Wikipedia-pages/index-enwiki'   # Lucene index directory path\n",
    "\n",
    "# enwiki doc generator object\n",
    "enwiki_corpus = MyCorpus(index_path, FIELDNAME)\n",
    "\n",
    "# to store ngrams with their frequencies\n",
    "unigram_counter = Counter()\n",
    "bigram_counter = Counter()\n",
    "trigram_counter = Counter()\n",
    "quadgram_counter = Counter()\n",
    "\n",
    "# sampling ngrams from one doc at a time and adding to Counters\n",
    "for doc in tqdm(enwiki_corpus, total=enwiki_corpus.numDocs):\n",
    "    # text pre-processing:\n",
    "    # blankline tokenization, then sentence tokenization, then word tokenization\n",
    "    sents_nested = [sent_tokenize(ss) for ss in blankline_tokenize(doc)]\n",
    "    sents = [sent for sublist in sents_nested for sent in sublist]\n",
    "    tokenized_sents = [word_tokenize(s) for s in sents]\n",
    "    \n",
    "    # POS tagging\n",
    "    tagged_sents = nltk.tag.pos_tag_sents(tokenized_sents, tagset='universal')\n",
    "    \n",
    "    # sampling ngrams from each sentence\n",
    "    for tagged_sent in tagged_sents:\n",
    "        unigrams = ngrams(tagged_sent, 1)\n",
    "        bigrams = ngrams(tagged_sent, 2)\n",
    "        trigrams = ngrams(tagged_sent, 3)\n",
    "        quadgrams = ngrams(tagged_sent, 4)\n",
    "        \n",
    "        # non-alphabetical ngram removal\n",
    "        unigrams = [ele[0] for ele in unigrams if ele[0][1].isalpha()]\n",
    "        bigrams = [bigram for bigram in bigrams if all(term.isalpha() for term,tag in bigram)]\n",
    "        trigrams = [trigram for trigram in trigrams if all(term.isalpha() for term,tag in trigram)]\n",
    "        quadgrams = [quadgram for quadgram in quadgrams if all(term.isalpha() for term,tag in quadgram)]\n",
    "        \n",
    "        # collocation POS filters\n",
    "        unigram_tags = ['NOUN']\n",
    "        bigram_tags = [('ADJ','NOUN'),('NOUN','NOUN')]\n",
    "        trigram_tags = [('ADJ','ADJ','NOUN'),('ADJ','NOUN','NOUN'),('NOUN','ADJ','NOUN'), \\\n",
    "            ('NOUN','NOUN','NOUN'),('NOUN','ADP','NOUN')]\n",
    "        quadgram_tags = [('NOUN','VERB','ADP','NOUN'),('NOUN','VERB','NOUN','NOUN'),('ADJ','NOUN','ADJ','NOUN'), \\\n",
    "            ('ADV','ADJ','NOUN','NOUN'),('NOUN','ADP','ADJ','NOUN'), \\\n",
    "            ('ADJ','NOUN','VERB','NOUN'),('NOUN','NOUN','ADP','NOUN'),('NOUN','ADJ','NOUN','NOUN')]\n",
    "        \n",
    "        # doing POS filteration and lowercasing\n",
    "        unigrams = [unigram.lower() for unigram,tag in unigrams if any(tag==ut for ut in unigram_tags)]\n",
    "        bigrams = [' '.join(term.lower() for term,tag in bigram) for bigram in bigrams if any([all(btgs[i]==bigram[i][1] for i in range(len(bigram))) for btgs in bigram_tags])]\n",
    "        trigrams = [' '.join(term.lower() for term,tag in trigram) for trigram in trigrams if any([all(ttgs[i]==trigram[i][1] for i in range(len(trigram))) for ttgs in trigram_tags])]\n",
    "        quadgrams = [' '.join(term.lower() for term,tag in quadgram) for quadgram in quadgrams if any([all(qtgs[i]==quadgram[i][1] for i in range(len(quadgram))) for qtgs in quadgram_tags])]\n",
    "        \n",
    "        # Add to Counters\n",
    "        unigram_counter.update(unigrams)\n",
    "        bigram_counter.update(bigrams)\n",
    "        trigram_counter.update(trigrams)\n",
    "        quadgram_counter.update(quadgrams)\n",
    "    \n",
    "with open('./counters-dump/unigram_counter.pickle', 'wb') as f:\n",
    "    pickle.dump(unigram_counter, f)\n",
    "    \n",
    "with open('./counters-dump/bigram_counter.pickle', 'wb') as f:\n",
    "    pickle.dump(bigram_counter, f)\n",
    "    \n",
    "with open('./counters-dump/trigram_counter.pickle', 'wb') as f:\n",
    "    pickle.dump(trigram_counter, f)\n",
    "\n",
    "with open('./counters-dump/quadgram_counter.pickle', 'wb') as f:\n",
    "    pickle.dump(quadgram_counter, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing query-generation-parallel.py for small number of docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./doc-query-dumps/1000-2000/1122/quadgram_doc1122.pickle', 'rb') as f:\n",
    "    bigram_doc10 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a manual of regional',\n",
       " 'citing a botanical name',\n",
       " 'dermatology titled nouvelle pratique',\n",
       " 'disease caused by microsporon',\n",
       " 'medium of low ph',\n",
       " 'physician born in nantes',\n",
       " 'was a french physician'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_doc10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./counters-dump/quadgram_counter.pickle', 'rb') as f:\n",
    "    quad = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['family of ukrainian industrialists',\n",
       " 'influence on various facets',\n",
       " 'manner of poetic expression',\n",
       " 'influence on ukrainian culture',\n",
       " 'figure with unmatched significance',\n",
       " 'poet located throughout ukraine',\n",
       " 'soviet union as part',\n",
       " 'series of ornamental textiles',\n",
       " 'vincent illuzzi of barre',\n",
       " 'tipperary hill in syracuse',\n",
       " 'shevchenko park in northeast',\n",
       " 'taras shevchenko in curitiba',\n",
       " 'bronze bust by lysenko',\n",
       " 'lusavorich cathedral in yerevan',\n",
       " 'cultural garden in rockefeller',\n",
       " 'anlæg park in copenhagen',\n",
       " 'ii won worst picture',\n",
       " 'east across northern pakistan',\n",
       " 'mountain valleys at altitudes',\n",
       " 'climate with dry winters']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(quad)[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# create a counter\n",
    "my_counter = Counter(['apple', 'banana', 'apple', 'orange', 'banana', 'apple'])\n",
    "\n",
    "# write the counter to a JSON file\n",
    "with open('counter.json', 'w') as f:\n",
    "    json.dump(my_counter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'apple': 3, 'banana': 2, 'orange': 1})\n"
     ]
    }
   ],
   "source": [
    "# read the counter from the JSON file\n",
    "with open('counter.json', 'r') as f:\n",
    "    loaded_counter = Counter(json.load(f))\n",
    "\n",
    "print(loaded_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 999999),\n",
       " (1000000, 1999999),\n",
       " (2000000, 2999999),\n",
       " (3000000, 3999999),\n",
       " (4000000, 4999999),\n",
       " (5000000, 5999999),\n",
       " (6000000, 6584625)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 1000000\n",
    "[(l[0],l[-1]) for l in (range(6584626)[i:i+step] for i in range(6584626)[::step])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./doc-query-dumps/900000-999999/counters_docs_999000-999999.json', 'r') as f:\n",
    "    # count = 0\n",
    "    loaded = []\n",
    "    for line in f:\n",
    "        counter_dict = json.loads(line)\n",
    "        new_dict = {int(key): value for key, value in counter_dict.items()}\n",
    "        loaded.append(new_dict)\n",
    "        # count += 1\n",
    "        # if count == 10:\n",
    "        #     break\n",
    "        # loaded = json.load(line)\n",
    "        # print(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "docids = [list(k.keys())[0] for k in loaded]\n",
    "\n",
    "# all([int(docid) in range(0,1000) for docid in docids])\n",
    "print(len(docids))\n",
    "# docids.index(999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[999000, 999001, 999002, 999003, 999004, 999005, 999006, 999007, 999008, 999009, 999010, 999011, 999012, 999013, 999014, 999015, 999016, 999017, 999018, 999019, 999020, 999021, 999022, 999023, 999024, 999025, 999026, 999027, 999028, 999029, 999030, 999031, 999032, 999033, 999034, 999035, 999036, 999037, 999038, 999039, 999040, 999041, 999042, 999043, 999044, 999045, 999046, 999047, 999048, 999049, 999050, 999051, 999052, 999053, 999054, 999055, 999056, 999057, 999058, 999059, 999060, 999061, 999062, 999063, 999064, 999065, 999066, 999067, 999068, 999069, 999070, 999071, 999072, 999073, 999074, 999075, 999076, 999077, 999078, 999079, 999080, 999081, 999082, 999083, 999084, 999085, 999086, 999087, 999088, 999089, 999090, 999091, 999092, 999093, 999094, 999095, 999096, 999097, 999098, 999099, 999100, 999101, 999102, 999103, 999104, 999105, 999106, 999107, 999108, 999109, 999110, 999111, 999112, 999113, 999114, 999115, 999116, 999117, 999118, 999119, 999120, 999121, 999122, 999123, 999124, 999125, 999126, 999127, 999128, 999129, 999130, 999131, 999132, 999133, 999134, 999135, 999136, 999137, 999138, 999139, 999140, 999141, 999142, 999143, 999144, 999145, 999146, 999147, 999148, 999149, 999150, 999151, 999152, 999153, 999154, 999155, 999156, 999157, 999158, 999159, 999160, 999161, 999162, 999163, 999164, 999165, 999166, 999167, 999168, 999169, 999170, 999171, 999172, 999173, 999174, 999175, 999176, 999177, 999178, 999179, 999180, 999181, 999182, 999183, 999184, 999185, 999186, 999187, 999188, 999189, 999190, 999191, 999192, 999193, 999194, 999195, 999196, 999197, 999198, 999199, 999200, 999201, 999202, 999203, 999204, 999205, 999206, 999207, 999208, 999209, 999210, 999211, 999212, 999213, 999214, 999215, 999216, 999217, 999218, 999219, 999220, 999221, 999222, 999223, 999224, 999225, 999226, 999227, 999228, 999229, 999230, 999231, 999232, 999233, 999234, 999235, 999236, 999237, 999238, 999239, 999240, 999241, 999242, 999243, 999244, 999245, 999246, 999247, 999248, 999249, 999250, 999251, 999252, 999253, 999254, 999255, 999256, 999257, 999258, 999259, 999260, 999261, 999262, 999263, 999264, 999265, 999266, 999267, 999268, 999269, 999270, 999271, 999272, 999273, 999274, 999275, 999276, 999277, 999278, 999279, 999280, 999281, 999282, 999283, 999284, 999285, 999286, 999287, 999288, 999289, 999290, 999291, 999292, 999293, 999294, 999295, 999296, 999297, 999298, 999299, 999300, 999301, 999302, 999303, 999304, 999305, 999306, 999307, 999308, 999309, 999310, 999311, 999312, 999313, 999314, 999315, 999316, 999317, 999318, 999319, 999320, 999321, 999322, 999323, 999324, 999325, 999326, 999327, 999328, 999329, 999330, 999331, 999332, 999333, 999334, 999335, 999336, 999337, 999338, 999339, 999340, 999341, 999342, 999343, 999344, 999345, 999346, 999347, 999348, 999349, 999350, 999351, 999352, 999353, 999354, 999355, 999356, 999357, 999358, 999359, 999360, 999361, 999362, 999363, 999364, 999365, 999366, 999367, 999368, 999369, 999370, 999371, 999372, 999373, 999374, 999375, 999376, 999377, 999378, 999379, 999380, 999381, 999382, 999383, 999384, 999385, 999386, 999387, 999388, 999389, 999390, 999391, 999392, 999393, 999394, 999395, 999396, 999397, 999398, 999399, 999400, 999401, 999402, 999403, 999404, 999405, 999406, 999407, 999408, 999409, 999410, 999411, 999412, 999413, 999414, 999415, 999416, 999417, 999418, 999419, 999420, 999421, 999422, 999423, 999424, 999425, 999426, 999427, 999428, 999429, 999430, 999431, 999432, 999433, 999434, 999435, 999436, 999437, 999438, 999439, 999440, 999441, 999442, 999443, 999444, 999445, 999446, 999447, 999448, 999449, 999450, 999451, 999452, 999453, 999454, 999455, 999456, 999457, 999458, 999459, 999460, 999461, 999462, 999463, 999464, 999465, 999466, 999467, 999468, 999469, 999470, 999471, 999472, 999473, 999474, 999475, 999476, 999477, 999478, 999479, 999480, 999481, 999482, 999483, 999484, 999485, 999486, 999487, 999488, 999489, 999490, 999491, 999492, 999493, 999494, 999495, 999496, 999497, 999498, 999499, 999500, 999501, 999502, 999503, 999504, 999505, 999506, 999507, 999508, 999509, 999510, 999511, 999512, 999513, 999514, 999515, 999516, 999517, 999518, 999519, 999520, 999521, 999522, 999523, 999524, 999525, 999526, 999527, 999528, 999529, 999530, 999531, 999532, 999533, 999534, 999535, 999536, 999537, 999538, 999539, 999540, 999541, 999542, 999543, 999544, 999545, 999546, 999547, 999548, 999549, 999550, 999551, 999552, 999553, 999554, 999555, 999556, 999557, 999558, 999559, 999560, 999561, 999562, 999563, 999564, 999565, 999566, 999567, 999568, 999569, 999570, 999571, 999572, 999573, 999574, 999575, 999576, 999577, 999578, 999579, 999580, 999581, 999582, 999583, 999584, 999585, 999586, 999587, 999588, 999589, 999590, 999591, 999592, 999593, 999594, 999595, 999596, 999597, 999598, 999599, 999600, 999601, 999602, 999603, 999604, 999605, 999606, 999607, 999608, 999609, 999610, 999611, 999612, 999613, 999614, 999615, 999616, 999617, 999618, 999619, 999620, 999621, 999622, 999623, 999624, 999625, 999626, 999627, 999628, 999629, 999630, 999631, 999632, 999633, 999634, 999635, 999636, 999637, 999638, 999639, 999640, 999641, 999642, 999643, 999644, 999645, 999646, 999647, 999648, 999649, 999650, 999651, 999652, 999653, 999654, 999655, 999656, 999657, 999658, 999659, 999660, 999661, 999662, 999663, 999664, 999665, 999666, 999667, 999668, 999669, 999670, 999671, 999672, 999673, 999674, 999675, 999676, 999677, 999678, 999679, 999680, 999681, 999682, 999683, 999684, 999685, 999686, 999687, 999688, 999689, 999690, 999691, 999692, 999693, 999694, 999695, 999696, 999697, 999698, 999699, 999700, 999701, 999702, 999703, 999704, 999705, 999706, 999707, 999708, 999709, 999710, 999711, 999712, 999713, 999714, 999715, 999716, 999717, 999718, 999719, 999720, 999721, 999722, 999723, 999724, 999725, 999726, 999727, 999728, 999729, 999730, 999731, 999732, 999733, 999734, 999735, 999736, 999737, 999738, 999739, 999740, 999741, 999742, 999743, 999744, 999745, 999746, 999747, 999748, 999749, 999750, 999751, 999752, 999753, 999754, 999755, 999756, 999757, 999758, 999759, 999760, 999761, 999762, 999763, 999764, 999765, 999766, 999767, 999768, 999769, 999770, 999771, 999772, 999773, 999774, 999775, 999776, 999777, 999778, 999779, 999780, 999781, 999782, 999783, 999784, 999785, 999786, 999787, 999788, 999789, 999790, 999791, 999792, 999793, 999794, 999795, 999796, 999797, 999798, 999799, 999800, 999801, 999802, 999803, 999804, 999805, 999806, 999807, 999808, 999809, 999810, 999811, 999812, 999813, 999814, 999815, 999816, 999817, 999818, 999819, 999820, 999821, 999822, 999823, 999824, 999825, 999826, 999827, 999828, 999829, 999830, 999831, 999832, 999833, 999834, 999835, 999836, 999837, 999838, 999839, 999840, 999841, 999842, 999843, 999844, 999845, 999846, 999847, 999848, 999849, 999850, 999851, 999852, 999853, 999854, 999855, 999856, 999857, 999858, 999859, 999860, 999861, 999862, 999863, 999864, 999865, 999866, 999867, 999868, 999869, 999870, 999871, 999872, 999873, 999874, 999875, 999876, 999877, 999878, 999879, 999880, 999881, 999882, 999883, 999884, 999885, 999886, 999887, 999888, 999889, 999890, 999891, 999892, 999893, 999894, 999895, 999896, 999897, 999898, 999899, 999900, 999901, 999902, 999903, 999904, 999905, 999906, 999907, 999908, 999909, 999910, 999911, 999912, 999913, 999914, 999915, 999916, 999917, 999918, 999919, 999920, 999921, 999922, 999923, 999924, 999925, 999926, 999927, 999928, 999929, 999930, 999931, 999932, 999933, 999934, 999935, 999936, 999937, 999938, 999939, 999940, 999941, 999942, 999943, 999944, 999945, 999946, 999947, 999948, 999949, 999950, 999951, 999952, 999953, 999954, 999955, 999956, 999957, 999958, 999959, 999960, 999961, 999962, 999963, 999964, 999965, 999966, 999967, 999968, 999969, 999970, 999971, 999972, 999973, 999974, 999975, 999976, 999977, 999978, 999979, 999980, 999981, 999982, 999983, 999984, 999985, 999986, 999987, 999988, 999989, 999990, 999991, 999992, 999993, 999994, 999995, 999996, 999997, 999998, 999999]\n"
     ]
    }
   ],
   "source": [
    "print(docids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(docid in range(999000,1000000) for docid in docids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'game developed by bluesky': 1,\n",
       " 'baseball starring deion sanders': 1,\n",
       " 'series concluded with world': 1,\n",
       " 'use of real life': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded[-1][999999]['quadgram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./counters-dumps/0-999999/bigram_counter.pickle', 'rb') as f:\n",
    "    bigram = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15974145"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add all partial ngram counters to give total counters for each ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = './counters-dumps/'\n",
    "step = 1000000\n",
    "dir_names = [f'{l[0]}-{l[-1]}' for l in (range(6584626)[i:i+step] for i in range(6584626)[::step])]\n",
    "paths = [os.path.join(root_dir, dir_name) for dir_name in dir_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:12<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "total_unigram_counter = Counter()\n",
    "for path in tqdm(paths):\n",
    "    with open(os.path.join(path, 'unigram_counter.pickle'), 'rb') as f:\n",
    "        unigram_counter = pickle.load(f)\n",
    "    total_unigram_counter += unigram_counter\n",
    "\n",
    "with open('./counters-dumps/total/unigram_counter.pickle', 'wb') as f:\n",
    "    pickle.dump(total_unigram_counter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:58<00:00, 16.98s/it]\n"
     ]
    }
   ],
   "source": [
    "total_bigram_counter = Counter()\n",
    "for path in tqdm(paths):\n",
    "    with open(os.path.join(path, 'bigram_counter.pickle'), 'rb') as f:\n",
    "        bigram_counter = pickle.load(f)\n",
    "    total_bigram_counter += bigram_counter\n",
    "\n",
    "with open('./counters-dumps/total/bigram_counter.pickle', 'wb') as f:\n",
    "    pickle.dump(total_bigram_counter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:47<00:00, 23.92s/it]\n"
     ]
    }
   ],
   "source": [
    "total_trigram_counter = Counter()\n",
    "for path in tqdm(paths):\n",
    "    with open(os.path.join(path, 'trigram_counter.pickle'), 'rb') as f:\n",
    "        trigram_counter = pickle.load(f)\n",
    "    total_trigram_counter += trigram_counter\n",
    "\n",
    "with open('./counters-dumps/total/trigram_counter.pickle', 'wb') as f:\n",
    "    pickle.dump(total_trigram_counter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:00<00:00,  8.59s/it]\n"
     ]
    }
   ],
   "source": [
    "total_quadgram_counter = Counter()\n",
    "for path in tqdm(paths):\n",
    "    with open(os.path.join(path, 'quadgram_counter.pickle'), 'rb') as f:\n",
    "        quadgram_counter = pickle.load(f)\n",
    "    total_quadgram_counter += quadgram_counter\n",
    "\n",
    "with open('./counters-dumps/total/quadgram_counter.pickle', 'wb') as f:\n",
    "    pickle.dump(total_quadgram_counter, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding a suitable tf-cutoff for each ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 occurs 3567145 times\n",
      "2 occurs 184597 times\n",
      "3 occurs 45408 times\n",
      "4 occurs 19663 times\n",
      "5 occurs 10908 times\n",
      "6 occurs 6748 times\n",
      "7 occurs 4545 times\n",
      "8 occurs 3157 times\n",
      "9 occurs 2424 times\n",
      "10 occurs 1911 times\n",
      "11 occurs 1581 times\n",
      "12 occurs 1179 times\n",
      "13 occurs 946 times\n",
      "14 occurs 845 times\n",
      "15 occurs 694 times\n",
      "16 occurs 618 times\n",
      "17 occurs 550 times\n",
      "18 occurs 462 times\n",
      "19 occurs 384 times\n",
      "20 occurs 371 times\n",
      "21 occurs 301 times\n",
      "22 occurs 285 times\n",
      "23 occurs 274 times\n",
      "24 occurs 221 times\n",
      "25 occurs 243 times\n",
      "26 occurs 196 times\n",
      "27 occurs 175 times\n",
      "28 occurs 146 times\n",
      "29 occurs 145 times\n",
      "30 occurs 135 times\n",
      "31 occurs 111 times\n",
      "32 occurs 121 times\n",
      "33 occurs 87 times\n",
      "34 occurs 100 times\n",
      "35 occurs 100 times\n",
      "36 occurs 84 times\n",
      "37 occurs 81 times\n",
      "38 occurs 59 times\n",
      "39 occurs 62 times\n",
      "40 occurs 62 times\n",
      "41 occurs 73 times\n",
      "42 occurs 69 times\n",
      "43 occurs 53 times\n",
      "44 occurs 59 times\n",
      "45 occurs 58 times\n",
      "46 occurs 50 times\n",
      "47 occurs 50 times\n",
      "48 occurs 62 times\n",
      "49 occurs 54 times\n",
      "50 occurs 36 times\n",
      "51 occurs 37 times\n",
      "52 occurs 36 times\n",
      "53 occurs 36 times\n",
      "54 occurs 34 times\n",
      "55 occurs 27 times\n",
      "56 occurs 30 times\n",
      "57 occurs 36 times\n",
      "58 occurs 28 times\n",
      "59 occurs 35 times\n",
      "60 occurs 35 times\n",
      "61 occurs 28 times\n",
      "62 occurs 26 times\n",
      "63 occurs 27 times\n",
      "64 occurs 19 times\n",
      "65 occurs 22 times\n",
      "66 occurs 21 times\n",
      "67 occurs 26 times\n",
      "68 occurs 19 times\n",
      "69 occurs 11 times\n",
      "70 occurs 25 times\n",
      "71 occurs 21 times\n",
      "72 occurs 18 times\n",
      "73 occurs 21 times\n",
      "74 occurs 18 times\n",
      "75 occurs 11 times\n",
      "76 occurs 18 times\n",
      "77 occurs 15 times\n",
      "78 occurs 13 times\n",
      "79 occurs 24 times\n",
      "80 occurs 13 times\n",
      "81 occurs 15 times\n",
      "82 occurs 16 times\n",
      "83 occurs 6 times\n",
      "84 occurs 11 times\n",
      "85 occurs 7 times\n",
      "86 occurs 12 times\n",
      "87 occurs 7 times\n",
      "88 occurs 7 times\n",
      "89 occurs 10 times\n",
      "90 occurs 10 times\n",
      "91 occurs 7 times\n",
      "92 occurs 15 times\n",
      "93 occurs 7 times\n",
      "94 occurs 14 times\n",
      "95 occurs 11 times\n",
      "96 occurs 15 times\n",
      "97 occurs 10 times\n",
      "98 occurs 14 times\n",
      "99 occurs 4 times\n",
      "100 occurs 7 times\n",
      "101 occurs 8 times\n",
      "102 occurs 6 times\n",
      "103 occurs 3 times\n",
      "104 occurs 8 times\n",
      "105 occurs 12 times\n",
      "106 occurs 9 times\n",
      "107 occurs 4 times\n",
      "108 occurs 8 times\n",
      "109 occurs 8 times\n",
      "110 occurs 3 times\n",
      "111 occurs 7 times\n",
      "112 occurs 6 times\n",
      "113 occurs 4 times\n",
      "114 occurs 4 times\n",
      "115 occurs 8 times\n",
      "116 occurs 5 times\n",
      "117 occurs 4 times\n",
      "118 occurs 2 times\n",
      "119 occurs 5 times\n",
      "120 occurs 6 times\n",
      "121 occurs 4 times\n",
      "122 occurs 5 times\n",
      "123 occurs 7 times\n",
      "124 occurs 3 times\n",
      "125 occurs 7 times\n",
      "126 occurs 2 times\n",
      "127 occurs 4 times\n",
      "128 occurs 5 times\n",
      "129 occurs 10 times\n",
      "130 occurs 6 times\n",
      "131 occurs 3 times\n",
      "132 occurs 2 times\n",
      "133 occurs 5 times\n",
      "134 occurs 4 times\n",
      "135 occurs 4 times\n",
      "136 occurs 3 times\n",
      "137 occurs 2 times\n",
      "138 occurs 6 times\n",
      "139 occurs 3 times\n",
      "140 occurs 4 times\n",
      "141 occurs 6 times\n",
      "142 occurs 5 times\n",
      "143 occurs 5 times\n",
      "144 occurs 5 times\n",
      "145 occurs 3 times\n",
      "146 occurs 1 times\n",
      "147 occurs 2 times\n",
      "148 occurs 6 times\n",
      "149 occurs 1 times\n",
      "150 occurs 3 times\n",
      "151 occurs 5 times\n",
      "152 occurs 3 times\n",
      "153 occurs 3 times\n",
      "154 occurs 4 times\n",
      "155 occurs 2 times\n",
      "156 occurs 3 times\n",
      "157 occurs 3 times\n",
      "158 occurs 5 times\n",
      "159 occurs 1 times\n",
      "160 occurs 3 times\n",
      "161 occurs 1 times\n",
      "162 occurs 3 times\n",
      "163 occurs 1 times\n",
      "165 occurs 1 times\n",
      "166 occurs 5 times\n",
      "167 occurs 1 times\n",
      "168 occurs 5 times\n",
      "169 occurs 4 times\n",
      "172 occurs 2 times\n",
      "173 occurs 4 times\n",
      "174 occurs 2 times\n",
      "175 occurs 2 times\n",
      "177 occurs 1 times\n",
      "178 occurs 1 times\n",
      "179 occurs 2 times\n",
      "180 occurs 3 times\n",
      "181 occurs 2 times\n",
      "182 occurs 1 times\n",
      "184 occurs 1 times\n",
      "185 occurs 1 times\n",
      "186 occurs 1 times\n",
      "187 occurs 2 times\n",
      "188 occurs 1 times\n",
      "189 occurs 2 times\n",
      "191 occurs 1 times\n",
      "192 occurs 3 times\n",
      "193 occurs 1 times\n",
      "194 occurs 2 times\n",
      "195 occurs 3 times\n",
      "196 occurs 1 times\n",
      "197 occurs 3 times\n",
      "198 occurs 2 times\n",
      "199 occurs 2 times\n",
      "201 occurs 4 times\n",
      "203 occurs 2 times\n",
      "204 occurs 1 times\n",
      "205 occurs 2 times\n",
      "206 occurs 1 times\n",
      "207 occurs 2 times\n",
      "208 occurs 2 times\n",
      "209 occurs 3 times\n",
      "210 occurs 1 times\n",
      "211 occurs 3 times\n",
      "213 occurs 2 times\n",
      "214 occurs 1 times\n",
      "215 occurs 1 times\n",
      "216 occurs 2 times\n",
      "217 occurs 2 times\n",
      "218 occurs 2 times\n",
      "219 occurs 2 times\n",
      "220 occurs 2 times\n",
      "221 occurs 2 times\n",
      "226 occurs 2 times\n",
      "228 occurs 1 times\n",
      "229 occurs 1 times\n",
      "230 occurs 2 times\n",
      "231 occurs 1 times\n",
      "232 occurs 2 times\n",
      "234 occurs 2 times\n",
      "236 occurs 1 times\n",
      "237 occurs 3 times\n",
      "238 occurs 2 times\n",
      "239 occurs 1 times\n",
      "241 occurs 1 times\n",
      "242 occurs 1 times\n",
      "243 occurs 1 times\n",
      "245 occurs 4 times\n",
      "246 occurs 2 times\n",
      "247 occurs 1 times\n",
      "248 occurs 1 times\n",
      "249 occurs 1 times\n",
      "250 occurs 3 times\n",
      "251 occurs 2 times\n",
      "252 occurs 1 times\n",
      "253 occurs 2 times\n",
      "254 occurs 1 times\n",
      "255 occurs 1 times\n",
      "256 occurs 1 times\n",
      "257 occurs 1 times\n",
      "259 occurs 1 times\n",
      "260 occurs 1 times\n",
      "261 occurs 1 times\n",
      "262 occurs 2 times\n",
      "264 occurs 1 times\n",
      "267 occurs 1 times\n",
      "269 occurs 1 times\n",
      "270 occurs 2 times\n",
      "272 occurs 1 times\n",
      "273 occurs 1 times\n",
      "274 occurs 1 times\n",
      "275 occurs 1 times\n",
      "276 occurs 1 times\n",
      "278 occurs 1 times\n",
      "280 occurs 1 times\n",
      "283 occurs 1 times\n",
      "285 occurs 1 times\n",
      "286 occurs 1 times\n",
      "288 occurs 2 times\n",
      "289 occurs 2 times\n",
      "292 occurs 1 times\n",
      "293 occurs 1 times\n",
      "294 occurs 1 times\n",
      "295 occurs 1 times\n",
      "298 occurs 1 times\n",
      "301 occurs 1 times\n",
      "303 occurs 1 times\n",
      "305 occurs 1 times\n",
      "306 occurs 1 times\n",
      "307 occurs 2 times\n",
      "311 occurs 1 times\n",
      "312 occurs 1 times\n",
      "314 occurs 1 times\n",
      "316 occurs 1 times\n",
      "317 occurs 1 times\n",
      "320 occurs 1 times\n",
      "322 occurs 1 times\n",
      "327 occurs 1 times\n",
      "328 occurs 1 times\n",
      "332 occurs 1 times\n",
      "334 occurs 2 times\n",
      "335 occurs 1 times\n",
      "337 occurs 1 times\n",
      "339 occurs 1 times\n",
      "343 occurs 1 times\n",
      "356 occurs 1 times\n",
      "359 occurs 1 times\n",
      "360 occurs 1 times\n",
      "361 occurs 1 times\n",
      "363 occurs 1 times\n",
      "366 occurs 1 times\n",
      "373 occurs 1 times\n",
      "376 occurs 1 times\n",
      "385 occurs 1 times\n",
      "386 occurs 1 times\n",
      "388 occurs 1 times\n",
      "389 occurs 1 times\n",
      "390 occurs 1 times\n",
      "392 occurs 1 times\n",
      "393 occurs 1 times\n",
      "399 occurs 1 times\n",
      "404 occurs 1 times\n",
      "405 occurs 2 times\n",
      "406 occurs 2 times\n",
      "408 occurs 1 times\n",
      "409 occurs 1 times\n",
      "414 occurs 2 times\n",
      "438 occurs 1 times\n",
      "439 occurs 1 times\n",
      "440 occurs 1 times\n",
      "445 occurs 1 times\n",
      "450 occurs 1 times\n",
      "453 occurs 1 times\n",
      "457 occurs 1 times\n",
      "478 occurs 1 times\n",
      "482 occurs 1 times\n",
      "484 occurs 2 times\n",
      "490 occurs 1 times\n",
      "493 occurs 1 times\n",
      "497 occurs 1 times\n",
      "505 occurs 1 times\n",
      "509 occurs 2 times\n",
      "510 occurs 1 times\n",
      "514 occurs 1 times\n",
      "523 occurs 1 times\n",
      "526 occurs 2 times\n",
      "529 occurs 1 times\n",
      "561 occurs 1 times\n",
      "564 occurs 1 times\n",
      "603 occurs 1 times\n",
      "605 occurs 1 times\n",
      "618 occurs 1 times\n",
      "621 occurs 1 times\n",
      "626 occurs 1 times\n",
      "655 occurs 1 times\n",
      "683 occurs 1 times\n",
      "716 occurs 1 times\n",
      "753 occurs 1 times\n",
      "759 occurs 1 times\n",
      "781 occurs 1 times\n",
      "801 occurs 1 times\n",
      "809 occurs 1 times\n",
      "924 occurs 1 times\n",
      "930 occurs 1 times\n",
      "982 occurs 1 times\n",
      "991 occurs 1 times\n",
      "1012 occurs 1 times\n",
      "1041 occurs 1 times\n",
      "1099 occurs 1 times\n",
      "1232 occurs 1 times\n",
      "1240 occurs 1 times\n",
      "1291 occurs 1 times\n",
      "1309 occurs 1 times\n",
      "1328 occurs 1 times\n",
      "1547 occurs 1 times\n",
      "1664 occurs 1 times\n",
      "1993 occurs 1 times\n",
      "2135 occurs 1 times\n",
      "2199 occurs 1 times\n",
      "2531 occurs 1 times\n",
      "11397 occurs 1 times\n"
     ]
    }
   ],
   "source": [
    "count_values = sorted(Counter(quadgram_counter.values()).items(), key=lambda x: x[0])\n",
    "\n",
    "# print frequency distribution\n",
    "for count, freq in count_values:\n",
    "    print(f'{count} occurs {freq} times')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngrams list truncation at specific no. of queries for each ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./counters-dumps/total/quadgram_counter.pickle', 'rb') as f:\n",
    "    quadgram_counter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_counter = quadgram_counter.most_common(1300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ngrams = [query for query,_ in top_counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as JSON\n",
    "with open('./final-queries/quadgram-queries.json', 'w') as f:\n",
    "    json.dump(top_ngrams, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add all ngrams into one JSON file for ALL Artificial Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all queries in one list\n",
    "all_queries = []\n",
    "\n",
    "# Set the directory path\n",
    "directory = './final-queries/'\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    # Check if the file ends with 'gram-queries.json'\n",
    "    if filename.endswith('gram-queries.json'):\n",
    "        # Load the JSON file\n",
    "        with open(os.path.join(directory, filename), 'r') as f:\n",
    "            queries = json.load(f)\n",
    "        all_queries.extend(queries)\n",
    "\n",
    "with open('./final-queries/all-queries.json', 'w') as f:\n",
    "    json.dump(all_queries, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4550000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_queries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
